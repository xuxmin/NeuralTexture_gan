
## Neural Texture

徐贤民 2020年12月7日

### epoch visualization

下面是使用 7/8 的 view, 7/8 的 light 数据进行训练的过程可视化。

一个 epoch 大概迭代 9000 多次, 每迭代 60 次, 就用模型生成效果图片, 最后组合成视频:
- http://182.92.112.211:7070/s/zDQnnrk3jKynTWP
- 前 6 个 epoch 的学习率为 0.0005, 后面学习率降低为 0.0001, 所以 epoch 6 以后光照的抖动看起来比前面小

每训练一个 epoch, 生成一段光照连续变化下的效果视频, 最后组合:
- http://182.92.112.211:7070/s/BnXbwoQ2BYgmbCs

### overfitting

上次 exp2 overfitting 问题可能是训练了太多的 epoch 导致的。

现在的结果如下:
- http://182.92.112.211:7070/s/T4pNgKLaiowFMRm
- 上面的视频在 12-14s 蛋的明暗变化有一个跳变, epoch 训练越多越明显, 这个现象还没有解决。


问题: **很难评价定量评价最终生成视频的好坏**。

首先训练过程中, 验证集的 MAE 损失是不断降低的(如下图), 这意味着单张图片合成的精度在升高, 人眼也能看出生成的图片效果更加好。

<img src="http://182.92.112.211:8080/images/2020/12/04/1.png" width=400>

但是生成的图片效果更好, 并不能保证生成的视频效果好, 会产生明暗跳变的这种不好的效果。所以很难确定到底训练到多少个 epoch.


### concatenation(16+9=25) 对比实验

输入 
- uv_map (3×256×256), 采样 neural texture 获得特征 Feature (16×256×256)
- normal(3×256×256)
- light dir (3×256×256)
- view dir (3×256×256)

exp1: Feature 的前 3 层 (3×256×256) 与 normal 逐元素相乘, 3-6 层与 light dir 逐元素相乘, 6-9 层与 view dir 逐元素相乘. 将变换后的特征 16×256×256 输入 UNet 生成图片

exp2: Feature(16×256×256) 与 normal, light dir, view dir 进行 concatenate, 获得 25×256×256 大小的特征输入 UNet 生成图片

exp1 与 exp2 除了上面两个不同外, 其他训练参数完全相同.

使用 7/8 的 view 与 1/8 的 light 数据进行训练, 训练了 60 个 epoch 后结果如下:

**单张图片对比**

![121bba1f971c588ff.png](http://182.92.112.211:8080/images/2020/12/04/121bba1f971c588ff.png)
![2.png](http://182.92.112.211:8080/images/2020/12/04/2.png)
![3.png](http://182.92.112.211:8080/images/2020/12/04/3.png)
![4.png](http://182.92.112.211:8080/images/2020/12/04/4.png)
![6.png](http://182.92.112.211:8080/images/2020/12/04/6.png)

**测试集误差比较**
- exp1: MAE=0.0174 MSE=0.0029
- exp2: MAE=0.0186 MSE=0.0033

根据上面的结果可以看出, 使用直接将 normal, light, view 加在 neural texture 后面(exp2的方法) 也可以训练出来, 最终的效果也差不多, exp1 稍微比 exp2 好一点。

**视频对比**
- http://182.92.112.211:7070/s/k8PSYrEAS5QcTqM
- 视频看起来感觉都差不多, 看不出来哪个更好


### 与不使用 GAN 进行对比

尝试去掉判别器以及判别器相关的损失，仅使用 L1 loss + VGG loss 进行训练。将训练出来的结果与之前的结果进行对比:

结果是: 不使用 GAN 也能训练出与先前非常相近的结果

![1.png](http://182.92.112.211:8080/images/2020/12/07/1.png)
![2.png](http://182.92.112.211:8080/images/2020/12/07/2.png)
![3.png](http://182.92.112.211:8080/images/2020/12/07/3.png)
![4.png](http://182.92.112.211:8080/images/2020/12/07/4.png)

视频对比:

http://182.92.112.211:7070/s/xQmFtwACRnJBPn8

从视频中可以看出, 不使用 GAN 训练出来的结果纹理有种一横一横的条纹的感觉

### different view/light

正在做, 还没有完成


